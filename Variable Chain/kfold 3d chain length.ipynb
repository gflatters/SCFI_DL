{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/ubuntu/data/code/Modules/\")\n",
    "import skimage\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "from albumentations import Compose,HorizontalFlip, VerticalFlip, ToFloat\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend\n",
    "from keras.models import Sequential\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, BatchNormalization, Flatten, Dropout\n",
    "from keras.optimizers import SGD,Adadelta\n",
    "import DataGenerator\n",
    "from albumentations import Compose,HorizontalFlip, VerticalFlip, ToFloat\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "import glob\n",
    "import CNN_Module as cnn_module\n",
    "import models\n",
    "import DataGenerator_3d\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6585\n",
      "1647\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "results=pickle.load(open('/home/ubuntu/data/code/chaining/3dchain_preds_final_ceph.p','rb'))\n",
    "train_preds = results[0]\n",
    "test_preds = results[1]\n",
    "print(len(train_preds))\n",
    "print(len(test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Get_Simple_Fluctuations_Average_Intensity as simp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding length data\n",
    "resistant_lengths = simp.getlengths('/home/ubuntu/data/cephdata/resistant/')\n",
    "sus_lengths = simp.getlengths('/home/ubuntu/data/cephdata/susceptible/')\n",
    "all_lengths = resistant_lengths+sus_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifying labels\n",
    "targets = simp.gettargets('/home/ubuntu/data/cephdata/resistant/','/home/ubuntu/data/cephdata/susceptible/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new dictionary with paths and lengths\n",
    "result_dict = {}\n",
    "for path, length, _ in all_lengths:\n",
    "    result_dict[path]=(length,targets[path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glue_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First find the cells in the train and test partitions\n",
    "test_cells = sorted(glue_code.partition_to_keys(list(test_preds.keys())))\n",
    "train_cells = sorted(glue_code.partition_to_keys(list(train_preds.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#go from list of cells, to list of lists of images from each cell\n",
    "cell_ims_test = glue_code.split_preds_into_cells(test_preds,test_cells)\n",
    "cell_ims_train = glue_code.split_preds_into_cells(train_preds,train_cells)\n",
    "\n",
    "#get the av score for susceptible, and proportion of images classified as susceptible\n",
    "cell_predictions_test = glue_code.get_cell_predictions(cell_ims_test,test_preds)\n",
    "cell_predictions_train = glue_code.get_cell_predictions(cell_ims_train,train_preds)\n",
    "#print(cell_predictions_test)\n",
    "\n",
    "#glue together CNN predictions and av/lengths/labels\n",
    "test_final = glue_code.glue_flucs_preds(cell_predictions_test,result_dict)\n",
    "train_final = glue_code.glue_flucs_preds(cell_predictions_train,result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr =(np.array(test_final)[:,1:].astype(float))\n",
    "train_arr =  (np.array(train_final)[:,1:].astype(float))\n",
    "\n",
    "np.random.shuffle(test_arr)\n",
    "np.random.shuffle(train_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split off the labels which we are trying to predict, from the predictors\n",
    "Xtrain = train_arr[:,:-1]\n",
    "Ytrain = train_arr[:,-1]\n",
    "\n",
    "Xtest = test_arr[:,:-1]\n",
    "Ytest = test_arr[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7638888888888888\n"
     ]
    }
   ],
   "source": [
    "# train new algorithm\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier,BaggingClassifier,GradientBoostingClassifier\n",
    "#clf = AdaBoostClassifier(n_estimators=3, random_state=0)\n",
    "#clf = RandomForestClassifier(max_depth=1,n_estimators=1, random_state=0)\n",
    "clf = GradientBoostingClassifier(n_estimators=10,max_depth=1)\n",
    "clf.fit(Xtrain, Ytrain)\n",
    "print(clf.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
