{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/home/ubuntu/data/code/Modules/\")\n",
    "import skimage\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gc\n",
    "from albumentations import Compose,HorizontalFlip, VerticalFlip, ToFloat\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend\n",
    "from keras.models import Sequential\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, BatchNormalization, Flatten, Dropout\n",
    "from keras.optimizers import SGD,Adadelta\n",
    "import DataGenerator\n",
    "from albumentations import Compose,HorizontalFlip, VerticalFlip, ToFloat\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "import glob\n",
    "import CNN_Module as cnn_module\n",
    "import models\n",
    "import DataGenerator_3d\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8208\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#3D\n",
    "val_acc, preds = pickle.load(open('/home/ubuntu/data/code/3dCNN/3d_kfold_final_ceph5.p','rb'))\n",
    "\n",
    "#2D\n",
    "#preds, val_acc, throw1, throw2 = pickle.load(open('/home/ubuntu/data/code/2dCNN/ceph_model2_lr001.p','rb'))\n",
    "\n",
    "'''preds = result_all[0]\n",
    "kfold_val_acc = result_all[1]\n",
    "kfold_acc = result_all[2]\n",
    "kfold_val_loss = result_all[3]\n",
    "'''\n",
    "\n",
    "#print(len(results[3]))\n",
    "#train_preds = results[1]\n",
    "#test_preds = results[3]\n",
    "#print(train_preds)\n",
    "print(len(preds))\n",
    "#print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1641\n",
      "1641\n",
      "1641\n",
      "1641\n",
      "1644\n"
     ]
    }
   ],
   "source": [
    "#split preds into test train\n",
    "fold_split_idx = len(preds)//5\n",
    "\n",
    "fold1 = dict(list(preds.items())[:fold_split_idx])\n",
    "fold2 = dict(list(preds.items())[fold_split_idx:2*fold_split_idx])\n",
    "fold3 = dict(list(preds.items())[2*fold_split_idx:3*fold_split_idx])\n",
    "fold4 = dict(list(preds.items())[3*fold_split_idx:4*fold_split_idx])\n",
    "fold5 = dict(list(preds.items())[4*fold_split_idx:])\n",
    "\n",
    "print(len(fold1))\n",
    "print(len(fold2))\n",
    "print(len(fold3))\n",
    "print(len(fold4))\n",
    "print(len(fold5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1316\n",
      "328\n"
     ]
    }
   ],
   "source": [
    "#change this badboi\n",
    "fold = fold5\n",
    "#l = list(fold.items())\n",
    "#random.shuffle(l)\n",
    "#fold = dict(l)\n",
    "\n",
    "split_idx = len(fold)//5\n",
    "preds_train = dict(list(fold.items())[split_idx:])\n",
    "preds_test = dict(list(fold.items())[:split_idx])\n",
    "\n",
    "print(len(preds_train))\n",
    "print(len(preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1316\n",
      "328\n"
     ]
    }
   ],
   "source": [
    "# need to re-format the train results\n",
    "#for 3d use preds[0], for 2d remove [0], in [preds[0] for preds in list(keys1)]\n",
    "keys1, values1 = preds_train.keys(), preds_train.values()\n",
    "just_names1 = [preds[0] for preds in list(keys1)]\n",
    "new_train_preds = dict(zip(just_names1,values1))\n",
    "train_preds = new_train_preds\n",
    "print(len(train_preds))\n",
    "\n",
    "keys2, values2 = preds_test.keys(), preds_test.values()\n",
    "just_names2 = [preds[0] for preds in list(keys2)]\n",
    "new_test_preds = dict(zip(just_names2,values2))\n",
    "test_preds = new_test_preds\n",
    "print(len(test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = [train_preds, test_preds]\n",
    "#print(result)\n",
    "#pickle.dump(result,open('/home/ubuntu/data/code/chaining/3dchain_preds_final_final_cipro.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pickle\\nresults=pickle.load(open('/home/ubuntu/data/code/chaining/3dchain_preds_final_ceph2.p','rb'))\\ntrain_preds = results[0]\\ntest_preds = results[1]\\nprint(len(train_preds))\\nprint(len(test_preds))\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import pickle\n",
    "results=pickle.load(open('/home/ubuntu/data/code/chaining/3dchain_preds_final_ceph2.p','rb'))\n",
    "train_preds = results[0]\n",
    "test_preds = results[1]\n",
    "print(len(train_preds))\n",
    "print(len(test_preds))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Get_Simple_Fluctuations_Average_Intensity as simp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507\n",
      "449\n"
     ]
    }
   ],
   "source": [
    "# finding fluc data\n",
    "res_flucs_csv =  simp.flucs_from_csv('/home/ubuntu/data/cephdata/resistant/')\n",
    "sus_flucs_csv = simp.flucs_from_csv('/home/ubuntu/data/cephdata/susceptible/')\n",
    "#combine dictionaries\n",
    "all_flucs = {**res_flucs_csv, **sus_flucs_csv} \n",
    "print(len(all_flucs))\n",
    "\n",
    "res_lengths = simp.getlengths('/home/ubuntu/data/cephdata/resistant/')\n",
    "sus_lengths = simp.getlengths('/home/ubuntu/data/cephdata/susceptible/')\n",
    "all_lengths = res_lengths+sus_lengths\n",
    "print(len(all_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449\n"
     ]
    }
   ],
   "source": [
    "# identifying labels\n",
    "targets = simp.gettargets('/home/ubuntu/data/cephdata/resistant/','/home/ubuntu/data/cephdata/susceptible/')\n",
    "#print(targets)\n",
    "print(len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449\n"
     ]
    }
   ],
   "source": [
    "# create new dictionary with paths and lengths\n",
    "result_dict = {}\n",
    "i=0\n",
    "for path, length, _ in all_lengths:\n",
    "    i+=1\n",
    "    #print(i)\n",
    "    #print(length)\n",
    "    #print(all_flucs[path])\n",
    "    #print(targets[path])\n",
    "    result_dict[path]=(length,all_flucs[path],targets[path])\n",
    "print(len(result_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glue_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n",
      "1316\n",
      "15\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "#First find the cells in the train and test partitions\n",
    "print(len(test_preds))\n",
    "print(len(train_preds))\n",
    "test_cells = sorted(glue_code.partition_to_keys(list(test_preds.keys())))\n",
    "train_cells = sorted(glue_code.partition_to_keys(list(train_preds.keys())))\n",
    "print(len(test_cells))\n",
    "print(len(train_cells))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "#go from list of cells, to list of lists of images from each cell\n",
    "cell_ims_test = glue_code.split_preds_into_cells(test_preds,test_cells)\n",
    "cell_ims_train = glue_code.split_preds_into_cells(train_preds,train_cells)\n",
    "\n",
    "#get the av score for susceptible, and proportion of images classified as susceptible\n",
    "cell_predictions_test = glue_code.get_cell_predictions(cell_ims_test,test_preds)\n",
    "cell_predictions_train = glue_code.get_cell_predictions(cell_ims_train,train_preds)\n",
    "\n",
    "#glue together CNN predictions and fluctuation/av/lengths/labels\n",
    "test_final = glue_code.glue_flucs_preds(cell_predictions_test,result_dict)\n",
    "train_final = glue_code.glue_flucs_preds(cell_predictions_train,result_dict)\n",
    "print(len(test_final))\n",
    "print(len(train_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr =(np.array(test_final)[:,1:].astype(float))\n",
    "train_arr =  (np.array(train_final)[:,1:].astype(float))\n",
    "\n",
    "np.random.shuffle(test_arr)\n",
    "np.random.shuffle(train_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split off the labels which we are trying to predict, from the predictors\n",
    "Xtrain = train_arr[:,:-1]\n",
    "Ytrain = train_arr[:,-1]\n",
    "\n",
    "Xtest = test_arr[:,:-1]\n",
    "Ytest = test_arr[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "190\n"
     ]
    }
   ],
   "source": [
    "#find overall accuracy of model without additional nets\n",
    "res_preds=[]\n",
    "sus_preds=[]\n",
    "keys, values = test_preds.keys(), test_preds.values()\n",
    "keys=list(keys)\n",
    "values = list(values)\n",
    "\n",
    "for i in np.arange(len(keys)):\n",
    "    if \"resistant\" in keys[i]:\n",
    "        res_preds.append((keys[i],values[i]))\n",
    "        \n",
    "        #print(list(keys))\n",
    "        #res_preds.append(path_preds, values)\n",
    "    if \"susceptible\" in keys[i]:\n",
    "        sus_preds.append((keys[i],values[i]))\n",
    "print(len(res_preds))\n",
    "print(len(sus_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res acc = 0.4057971014492754\n",
      "sus acc = 0.9052631578947369\n",
      "total acc = 0.6951219512195121\n"
     ]
    }
   ],
   "source": [
    "res_count = 0\n",
    "\n",
    "sus_count = 0\n",
    "for data in res_preds:\n",
    "    if data[1][0] > 0.5:\n",
    "        res_count += 1\n",
    "for data in sus_preds:\n",
    "    if data[1][1] > 0.5:\n",
    "        sus_count += 1\n",
    "print('res acc =', res_count/len(\n",
    "    res_preds))\n",
    "print('sus acc =', sus_count/len(sus_preds))\n",
    "print('total acc =', (sus_count+res_count)/(len(sus_preds)+len(res_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.6666666666666666\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.8\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.7333333333333333\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8666666666666667\n",
      "0.8666666666666667\n",
      "0.8666666666666667\n",
      "0.8666666666666667\n",
      "0.8666666666666667\n",
      "0.8666666666666667\n",
      "0.8666666666666667\n",
      "0.8666666666666667\n",
      "0.8666666666666667\n",
      "0.8666666666666667\n",
      "0.8666666666666667\n",
      "0.8666666666666667\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8\n",
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "# train new algorithm\n",
    "scores = []\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier,BaggingClassifier,GradientBoostingClassifier\n",
    "for i in np.arange(1,100):\n",
    "\n",
    "    #clf = AdaBoostClassifier()\n",
    "    clf = AdaBoostClassifier(n_estimators=i, random_state=0)\n",
    "    clf.fit(Xtrain, Ytrain)\n",
    "    scores.append(clf.score(Xtest, Ytest))\n",
    "    print(clf.score(Xtest, Ytest))\n",
    "print(max(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5263157894736842\n"
     ]
    }
   ],
   "source": [
    "# train new algorithm\n",
    "#clf = RandomForestClassifier()\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(Xtrain, Ytrain)\n",
    "print(clf.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8055555555555556\n"
     ]
    }
   ],
   "source": [
    "# train new algorithm\n",
    "#clf = GradientBoostingClassifier()\n",
    "clf = GradientBoostingClassifier(n_estimators=10,max_depth=1)\n",
    "clf.fit(Xtrain, Ytrain)\n",
    "print(clf.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(Xtrain, Ytrain)\n",
    "print(clf.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8055555555555556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(Xtrain, Ytrain)\n",
    "print(clf.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(Xtrain, Ytrain)\n",
    "print(clf.score(Xtest, Ytest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
